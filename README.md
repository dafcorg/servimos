# servimos
Tomar un modelo preentrenado y publicarlo como una API que corre sobre una instancia con GPU en la nube.

Cargar un modelo de ML preentrenado.

Crear una API sencilla usando FastAPI.

Ejecutarla en una m√°quina con GPU en la nube.

Hacerle peticiones desde un cliente.
